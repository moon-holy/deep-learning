{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 残差块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_planes, out_planes, stride=1, groups=1, dilation=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=dilation, groups=groups, bias=False, dilation=dilation)\n",
    "\n",
    "\n",
    "def conv1x1(in_planes, out_planes, stride=1):\n",
    "    \"\"\"1x1 convolution\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('BasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in BasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicBlock(\n",
       "  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 应用于resnet中的残差模块\n",
    "net = BasicBlock(256, 256)\n",
    "display(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottleneck Residual Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        width = int(planes * (base_width / 64.)) * groups\n",
    "        # Both self.conv2 and self.downsample layers downsample the input when stride != 1\n",
    "        self.conv1 = conv1x1(inplanes, width)\n",
    "        self.bn1 = norm_layer(width)\n",
    "        self.conv2 = conv3x3(width, width, stride, groups, dilation)\n",
    "        self.bn2 = norm_layer(width)\n",
    "        self.conv3 = conv1x1(width, planes * self.expansion)\n",
    "        self.bn3 = norm_layer(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bottleneck(\n",
       "  (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = Bottleneck(256, 256)\n",
    "display(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, pool_proj):\n",
    "        super(InceptionModule, self).__init__()\n",
    "        \n",
    "        # 1x1 卷积\n",
    "        self.conv1x1 = nn.Conv2d(in_channels, out_1x1, kernel_size=1)\n",
    "        \n",
    "        # 3x3 卷积和降维卷积\n",
    "        self.conv3x3_reduce = nn.Conv2d(in_channels, red_3x3, kernel_size=1)\n",
    "        self.conv3x3 = nn.Conv2d(red_3x3, out_3x3, kernel_size=3, padding=1)\n",
    "        \n",
    "        # 5x5 卷积和降维卷积\n",
    "        self.conv5x5_reduce = nn.Conv2d(in_channels, red_5x5, kernel_size=1)\n",
    "        self.conv5x5 = nn.Conv2d(red_5x5, out_5x5, kernel_size=5, padding=2)\n",
    "        \n",
    "        # 池化和降维卷积\n",
    "        self.pool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
    "        self.pool_proj = nn.Conv2d(in_channels, pool_proj, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_1x1 = torch.relu(self.conv1x1(x))\n",
    "        \n",
    "        output_3x3 = torch.relu(self.conv3x3_reduce(x))\n",
    "        output_3x3 = torch.relu(self.conv3x3(output_3x3))\n",
    "        \n",
    "        output_5x5 = torch.relu(self.conv5x5_reduce(x))\n",
    "        output_5x5 = torch.relu(self.conv5x5(output_5x5))\n",
    "        \n",
    "        output_pool = self.pool(x)\n",
    "        output_pool = torch.relu(self.pool_proj(output_pool))\n",
    "        \n",
    "        # 拼接所有特征图\n",
    "        outputs = [output_1x1, output_3x3, output_5x5, output_pool]\n",
    "        return torch.cat(outputs, dim=1)  # 在通道维度上拼接\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'网络的形状是 : '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "InceptionModule(\n",
       "  (conv1x1): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv3x3_reduce): Conv2d(3, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv3x3): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5x5_reduce): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (conv5x5): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "  (pool_proj): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'输出张量形状:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 160, 64, 64])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 假设输入通道数为 3，输出各部分通道数为 64, 128, 32, 32, 32, 32\n",
    "in_channels = 3\n",
    "out_1x1 = 64\n",
    "red_3x3 = 128\n",
    "out_3x3 = 32\n",
    "red_5x5 = 32\n",
    "out_5x5 = 32\n",
    "pool_proj = 32\n",
    "\n",
    "# 创建Inception模块\n",
    "inception = InceptionModule(in_channels, out_1x1, red_3x3, out_3x3, red_5x5, out_5x5, pool_proj)\n",
    "\n",
    "display(\"网络的形状是 : \", inception)\n",
    "\n",
    "# 随机生成一个输入张量，大小为 (batch_size, channels, height, width)\n",
    "batch_size = 1\n",
    "height, width = 64, 64\n",
    "inputs = torch.randn(batch_size, in_channels, height, width)\n",
    "\n",
    "# 使用Inception模块进行前向传播\n",
    "outputs = inception(inputs)\n",
    "\n",
    "\n",
    "# 输出每个模块的形状\n",
    "display(\"输出张量形状:\", outputs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Local Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLBlockND(nn.Module):\n",
    "    def __init__(self, in_channels, inter_channels=None, mode='embedded', \n",
    "                 dimension=3, bn_layer=True):\n",
    "        \"\"\"Implementation of Non-Local Block with 4 different pairwise functions but doesn't include subsampling trick\n",
    "        args:\n",
    "            in_channels: original channel size (1024 in the paper)\n",
    "            inter_channels: channel size inside the block if not specifed reduced to half (512 in the paper)\n",
    "            mode: supports Gaussian, Embedded Gaussian, Dot Product, and Concatenation\n",
    "            dimension: can be 1 (temporal), 2 (spatial), 3 (spatiotemporal)\n",
    "            bn_layer: whether to add batch norm\n",
    "        \"\"\"\n",
    "        super(NLBlockND, self).__init__()\n",
    "\n",
    "        assert dimension in [1, 2, 3]\n",
    "        \n",
    "        if mode not in ['gaussian', 'embedded', 'dot', 'concatenate']:\n",
    "            raise ValueError('`mode` must be one of `gaussian`, `embedded`, `dot` or `concatenate`')\n",
    "            \n",
    "        self.mode = mode\n",
    "        self.dimension = dimension\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.inter_channels = inter_channels\n",
    "\n",
    "        # the channel size is reduced to half inside the block\n",
    "        if self.inter_channels is None:\n",
    "            self.inter_channels = in_channels // 2\n",
    "            if self.inter_channels == 0:\n",
    "                self.inter_channels = 1\n",
    "        \n",
    "        # assign appropriate convolutional, max pool, and batch norm layers for different dimensions\n",
    "        if dimension == 3:\n",
    "            conv_nd = nn.Conv3d\n",
    "            max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
    "            bn = nn.BatchNorm3d\n",
    "        elif dimension == 2:\n",
    "            conv_nd = nn.Conv2d\n",
    "            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "            bn = nn.BatchNorm2d\n",
    "        else:\n",
    "            conv_nd = nn.Conv1d\n",
    "            max_pool_layer = nn.MaxPool1d(kernel_size=(2))\n",
    "            bn = nn.BatchNorm1d\n",
    "\n",
    "        # function g in the paper which goes through conv. with kernel size 1\n",
    "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "\n",
    "        # add BatchNorm layer after the last conv layer\n",
    "        if bn_layer:\n",
    "            self.W_z = nn.Sequential(\n",
    "                    conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1),\n",
    "                    bn(self.in_channels)\n",
    "                )\n",
    "            # from section 4.1 of the paper, initializing params of BN ensures that the initial state of non-local block is identity mapping\n",
    "            nn.init.constant_(self.W_z[1].weight, 0)\n",
    "            nn.init.constant_(self.W_z[1].bias, 0)\n",
    "        else:\n",
    "            self.W_z = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels, kernel_size=1)\n",
    "\n",
    "            # from section 3.3 of the paper by initializing Wz to 0, this block can be inserted to any existing architecture\n",
    "            nn.init.constant_(self.W_z.weight, 0)\n",
    "            nn.init.constant_(self.W_z.bias, 0)\n",
    "\n",
    "        # define theta and phi for all operations except gaussian\n",
    "        if self.mode == \"embedded\" or self.mode == \"dot\" or self.mode == \"concatenate\":\n",
    "            self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "            self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels, kernel_size=1)\n",
    "        \n",
    "        if self.mode == \"concatenate\":\n",
    "            self.W_f = nn.Sequential(\n",
    "                    nn.Conv2d(in_channels=self.inter_channels * 2, out_channels=1, kernel_size=1),\n",
    "                    nn.ReLU()\n",
    "                )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        args\n",
    "            x: (N, C, T, H, W) for dimension=3; (N, C, H, W) for dimension 2; (N, C, T) for dimension 1\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # (N, C, THW)\n",
    "        # this reshaping and permutation is from the spacetime_nonlocal function in the original Caffe2 implementation\n",
    "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
    "        g_x = g_x.permute(0, 2, 1)\n",
    "\n",
    "        if self.mode == \"gaussian\":\n",
    "            theta_x = x.view(batch_size, self.in_channels, -1)\n",
    "            phi_x = x.view(batch_size, self.in_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "        elif self.mode == \"embedded\" or self.mode == \"dot\":\n",
    "            theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
    "            phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
    "            theta_x = theta_x.permute(0, 2, 1)\n",
    "            f = torch.matmul(theta_x, phi_x)\n",
    "\n",
    "        elif self.mode == \"concatenate\":\n",
    "            theta_x = self.theta(x).view(batch_size, self.inter_channels, -1, 1)\n",
    "            phi_x = self.phi(x).view(batch_size, self.inter_channels, 1, -1)\n",
    "            \n",
    "            h = theta_x.size(2)\n",
    "            w = phi_x.size(3)\n",
    "            theta_x = theta_x.repeat(1, 1, 1, w)\n",
    "            phi_x = phi_x.repeat(1, 1, h, 1)\n",
    "            \n",
    "            concat = torch.cat([theta_x, phi_x], dim=1)\n",
    "            f = self.W_f(concat)\n",
    "            f = f.view(f.size(0), f.size(2), f.size(3))\n",
    "        \n",
    "        if self.mode == \"gaussian\" or self.mode == \"embedded\":\n",
    "            f_div_C = F.softmax(f, dim=-1)\n",
    "        elif self.mode == \"dot\" or self.mode == \"concatenate\":\n",
    "            N = f.size(-1) # number of position in x\n",
    "            f_div_C = f / N\n",
    "        \n",
    "        y = torch.matmul(f_div_C, g_x)\n",
    "        \n",
    "        # contiguous here just allocates contiguous chunk of memory\n",
    "        y = y.permute(0, 2, 1).contiguous()\n",
    "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
    "        \n",
    "        W_y = self.W_z(y)\n",
    "        # residual connection\n",
    "        z = W_y + x\n",
    "\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLBlockND(\n",
       "  (g): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (W_z): Sequential(\n",
       "    (0): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (theta): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "  (phi): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = NLBlockND(256)\n",
    "display(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpatialTransformer(nn.Module):\n",
    "    def __init__(self, in_channels, spatial_size):\n",
    "        super(SpatialTransformer, self).__init__()\n",
    "        self.localization_network = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 8, kernel_size=7),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(8, 10, kernel_size=5),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # 线性层用于预测空间变换参数\n",
    "        self.fc_loc = nn.Sequential(\n",
    "            nn.Linear(10 * spatial_size * spatial_size, 32),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(32, 3 * 2)  # 3个参数（旋转、缩放、平移）每个有2个值\n",
    "        )\n",
    "\n",
    "        # 采样器\n",
    "        self.sampler = torch.nn.functional.affine_grid\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 获取变换参数\n",
    "        theta = self.localization_network(x)\n",
    "        theta = theta.view(-1, 10 * 4 * 4)  # 假设输入大小是 (10, 4, 4)\n",
    "        theta = self.fc_loc(theta)\n",
    "        theta = theta.view(-1, 2, 3)  # 调整参数形状为 (batch_size, 2, 3)\n",
    "\n",
    "        # 生成采样网格\n",
    "        grid = self.sampler(theta, x.size())\n",
    "\n",
    "        # 执行空间变换\n",
    "        x_transformed = F.grid_sample(x, grid)\n",
    "\n",
    "        return x_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpatialTransformer(\n",
       "  (localization_network): Sequential(\n",
       "    (0): Conv2d(3, 8, kernel_size=(7, 7), stride=(1, 1))\n",
       "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Conv2d(8, 10, kernel_size=(5, 5), stride=(1, 1))\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc_loc): Sequential(\n",
       "    (0): Linear(in_features=90, out_features=32, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Linear(in_features=32, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = SpatialTransformer(3, 3)\n",
    "display(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNeXt Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNeXtBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, cardinality=32, stride=1):\n",
    "        super(ResNeXtBlock, self).__init__()\n",
    "\n",
    "        # 每个分组内部的通道数\n",
    "        group_channels = out_channels // cardinality\n",
    "        \n",
    "        # 第一个卷积层\n",
    "        self.conv1 = nn.Conv2d(in_channels, group_channels, kernel_size=1, stride=stride, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(group_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        # 分组卷积\n",
    "        self.conv2 = nn.Conv2d(group_channels, group_channels, kernel_size=3, stride=1, padding=1, groups=cardinality, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(group_channels)\n",
    "\n",
    "        # 最后一个卷积层\n",
    "        self.conv3 = nn.Conv2d(group_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        # 如果输入通道数和输出通道数不一致，使用 1x1 卷积调整\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = self.shortcut(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        x += shortcut\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDE_sources\\Ancona\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNeXtBlock(\n",
       "  (conv1): Conv2d(3, 0, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn1): BatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(0, 0, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "  (bn2): BatchNorm2d(0, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(0, 3, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn3): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (shortcut): Sequential()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = ResNeXtBlock(3, 3)\n",
    "display(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Channel Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logsumexp_2d(tensor):\n",
    "    tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "    s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "    outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "    return outputs\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class ChannelGate(nn.Module):\n",
    "\n",
    "    def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "        super(ChannelGate, self).__init__()\n",
    "        self.gate_channels = gate_channels\n",
    "        self.mlp = nn.Sequential(\n",
    "            Flatten(),\n",
    "            nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "            )\n",
    "        self.pool_types = pool_types\n",
    "        self.conv = nn.Conv2d(gate_channels, gate_channels // 2, kernel_size=(1, 1), stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        channel_att_sum = None\n",
    "        for pool_type in self.pool_types:\n",
    "            if pool_type=='avg':\n",
    "                avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( avg_pool )\n",
    "            elif pool_type=='max':\n",
    "                max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( max_pool )\n",
    "            elif pool_type=='lp':\n",
    "                lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                channel_att_raw = self.mlp( lp_pool )\n",
    "            elif pool_type=='lse':\n",
    "                # LSE pool only\n",
    "                lse_pool = logsumexp_2d(x)\n",
    "                channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "            if channel_att_sum is None:\n",
    "                channel_att_sum = channel_att_raw\n",
    "            else:\n",
    "                channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "        scale = F.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "        return self.conv(x * scale)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChannelGate(\n",
       "  (mlp): Sequential(\n",
       "    (0): Flatten()\n",
       "    (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "    (2): ReLU()\n",
       "    (3): Linear(in_features=16, out_features=256, bias=True)\n",
       "  )\n",
       "  (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = ChannelGate(256*2)\n",
    "display(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Flatten-1                 [-1, 2560]               0\n",
      "            Linear-2                  [-1, 160]         409,760\n",
      "              ReLU-3                  [-1, 160]               0\n",
      "            Linear-4                 [-1, 2560]         412,160\n",
      "           Flatten-5                 [-1, 2560]               0\n",
      "            Linear-6                  [-1, 160]         409,760\n",
      "              ReLU-7                  [-1, 160]               0\n",
      "            Linear-8                 [-1, 2560]         412,160\n",
      "            Conv2d-9       [-1, 1280, 128, 128]       3,278,080\n",
      "================================================================\n",
      "Total params: 4,921,920\n",
      "Trainable params: 4,921,920\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 160.00\n",
      "Forward/backward pass size (MB): 160.08\n",
      "Params size (MB): 18.78\n",
      "Estimated Total Size (MB): 338.86\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (256*10, 128, 128), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 128, 128])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn(1, 256*10, 128, 128)\n",
    "net(x1).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SE block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inspect import isfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swish(nn.Module):\n",
    "    \"\"\"\n",
    "    Swish activation function from 'Searching for Activation Functions,' https://arxiv.org/abs/1710.05941.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "    \n",
    "class HSwish(nn.Module):\n",
    "    \"\"\"\n",
    "    H-Swish activation function from 'Searching for MobileNetV3,' https://arxiv.org/abs/1905.02244.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    inplace : bool\n",
    "        Whether to use inplace version of the module.\n",
    "    \"\"\"\n",
    "    def __init__(self, inplace=False):\n",
    "        super(HSwish, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * F.relu6(x + 3.0, inplace=self.inplace) / 6.0\n",
    "    \n",
    "class HSigmoid(nn.Module):\n",
    "    \"\"\"\n",
    "    Approximated sigmoid function, so-called hard-version of sigmoid from 'Searching for MobileNetV3,'\n",
    "    https://arxiv.org/abs/1905.02244.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        return F.relu6(x + 3.0, inplace=True) / 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv1x1(in_channels,\n",
    "            out_channels,\n",
    "            stride=1,\n",
    "            groups=1,\n",
    "            bias=False):\n",
    "    \"\"\"\n",
    "    Convolution 1x1 layer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=1,\n",
    "        stride=stride,\n",
    "        groups=groups,\n",
    "        bias=bias)\n",
    "\n",
    "\n",
    "def conv3x3(in_channels,\n",
    "            out_channels,\n",
    "            stride=1,\n",
    "            padding=1,\n",
    "            dilation=1,\n",
    "            groups=1,\n",
    "            bias=False):\n",
    "    \"\"\"\n",
    "    Convolution 3x3 layer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    in_channels : int\n",
    "        Number of input channels.\n",
    "    out_channels : int\n",
    "        Number of output channels.\n",
    "    stride : int or tuple/list of 2 int, default 1\n",
    "        Strides of the convolution.\n",
    "    padding : int or tuple/list of 2 int, default 1\n",
    "        Padding value for convolution layer.\n",
    "    groups : int, default 1\n",
    "        Number of groups.\n",
    "    bias : bool, default False\n",
    "        Whether the layer uses a bias vector.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels=in_channels,\n",
    "        out_channels=out_channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=padding,\n",
    "        dilation=dilation,\n",
    "        groups=groups,\n",
    "        bias=bias)\n",
    "\n",
    "\n",
    "def depthwise_conv3x3(channels,\n",
    "                      stride):\n",
    "    \"\"\"\n",
    "    Depthwise convolution 3x3 layer.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of input/output channels.\n",
    "    strides : int or tuple/list of 2 int\n",
    "        Strides of the convolution.\n",
    "    \"\"\"\n",
    "    return nn.Conv2d(\n",
    "        in_channels=channels,\n",
    "        out_channels=channels,\n",
    "        kernel_size=3,\n",
    "        stride=stride,\n",
    "        padding=1,\n",
    "        groups=channels,\n",
    "        bias=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation_layer(activation):\n",
    "    \"\"\"\n",
    "    Create activation layer from string/function.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    activation : function, or str, or nn.Module\n",
    "        Activation function or name of activation function.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    nn.Module\n",
    "        Activation layer.\n",
    "    \"\"\"\n",
    "    assert (activation is not None)\n",
    "    if isfunction(activation):\n",
    "        return activation()\n",
    "    elif isinstance(activation, str):\n",
    "        if activation == \"relu\":\n",
    "            return nn.ReLU(inplace=True)\n",
    "        elif activation == \"relu6\":\n",
    "            return nn.ReLU6(inplace=True)\n",
    "        elif activation == \"swish\":\n",
    "            return Swish()\n",
    "        elif activation == \"hswish\":\n",
    "            return HSwish(inplace=True)\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "    else:\n",
    "        assert (isinstance(activation, nn.Module))\n",
    "        return activation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Squeeze-and-Excitation block from 'Squeeze-and-Excitation Networks,' https://arxiv.org/abs/1709.01507.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    channels : int\n",
    "        Number of channels.\n",
    "    reduction : int, default 16\n",
    "        Squeeze reduction value.\n",
    "    approx_sigmoid : bool, default False\n",
    "        Whether to use approximated sigmoid function.\n",
    "    activation : function, or str, or nn.Module\n",
    "        Activation function or name of activation function.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 channels,\n",
    "                 reduction=16,\n",
    "                 approx_sigmoid=False,\n",
    "                 activation=(lambda: nn.ReLU(inplace=True))):\n",
    "        super(SEBlock, self).__init__()\n",
    "        mid_cannels = channels // reduction\n",
    "\n",
    "        self.pool = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.conv1 = conv1x1(\n",
    "            in_channels=channels,\n",
    "            out_channels=mid_cannels,\n",
    "            bias=True)\n",
    "        self.activ = get_activation_layer(activation)\n",
    "        self.conv2 = conv1x1(\n",
    "            in_channels=mid_cannels,\n",
    "            out_channels=channels,\n",
    "            bias=True)\n",
    "        self.sigmoid = HSigmoid() if approx_sigmoid else nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        w = self.pool(x)\n",
    "        w = self.conv1(w)\n",
    "        w = self.activ(w)\n",
    "        w = self.conv2(w)\n",
    "        w = self.sigmoid(w)\n",
    "        x = x * w\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SEBlock(\n",
       "  (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (conv1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (activ): ReLU(inplace=True)\n",
       "  (conv2): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "se = SEBlock(256)\n",
    "display(se)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      " AdaptiveAvgPool2d-1            [-1, 256, 1, 1]               0\n",
      "            Conv2d-2             [-1, 16, 1, 1]           4,112\n",
      "              ReLU-3             [-1, 16, 1, 1]               0\n",
      "            Conv2d-4            [-1, 256, 1, 1]           4,352\n",
      "           Sigmoid-5            [-1, 256, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 8,464\n",
      "Trainable params: 8,464\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 16.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.03\n",
      "Estimated Total Size (MB): 16.04\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "x = (256, 128, 128)\n",
    "summary(se, x, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 128, 128])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = torch.randn(1, 256, 128, 128)\n",
    "se(x1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型设计\n",
    "# 输入\n",
    "x = torch.randn(1, 256*5, 128, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型\n",
    "cnn = SEBlock(256*5)\n",
    "csa = ChannelGate(256*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 128, 128])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x1 = cnn(x)\n",
    "x1 = torch.add(x1, x)\n",
    "display(x1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2560, 128, 128])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 对x 和 x1进行concat\n",
    "x2 = torch.cat((x1, x), dim = 1)\n",
    "display(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDE_sources\\Ancona\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 128, 128])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x2 = csa(x2)\n",
    "display(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1280, 128, 128])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x3 = torch.add(x2, x)\n",
    "display(x2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CCMBlock(nn.Module):\n",
    "    def __init__(self, input_channel):\n",
    "        super(CCMBlock, self).__init__()\n",
    "        self.cnn = SEBlock(input_channel)\n",
    "        self.csa = ChannelGate(input_channel * 2)\n",
    "        self.conv = nn.Conv2d(input_channel, input_channel, kernel_size=(1, 1), stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.cnn(x)\n",
    "        x1 = torch.add(x1, x)\n",
    "        x2 = torch.cat((x1, x), dim=1)\n",
    "        x2 = self.csa(x2)\n",
    "        return self.conv(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CCMBlock(\n",
       "  (cnn): SEBlock(\n",
       "    (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (conv1): Conv2d(1280, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (activ): ReLU(inplace=True)\n",
       "    (conv2): Conv2d(80, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (sigmoid): Sigmoid()\n",
       "  )\n",
       "  (csa): ChannelGate(\n",
       "    (mlp): Sequential(\n",
       "      (0): Flatten()\n",
       "      (1): Linear(in_features=2560, out_features=160, bias=True)\n",
       "      (2): ReLU()\n",
       "      (3): Linear(in_features=160, out_features=2560, bias=True)\n",
       "    )\n",
       "    (conv): Conv2d(2560, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       "  (conv): Conv2d(1280, 1280, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = CCMBlock(256*5)\n",
    "display(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IDE_sources\\Ancona\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      " AdaptiveAvgPool2d-1           [-1, 1280, 1, 1]               0\n",
      "            Conv2d-2             [-1, 80, 1, 1]         102,480\n",
      "              ReLU-3             [-1, 80, 1, 1]               0\n",
      "            Conv2d-4           [-1, 1280, 1, 1]         103,680\n",
      "           Sigmoid-5           [-1, 1280, 1, 1]               0\n",
      "           SEBlock-6       [-1, 1280, 128, 128]               0\n",
      "           Flatten-7                 [-1, 2560]               0\n",
      "            Linear-8                  [-1, 160]         409,760\n",
      "              ReLU-9                  [-1, 160]               0\n",
      "           Linear-10                 [-1, 2560]         412,160\n",
      "          Flatten-11                 [-1, 2560]               0\n",
      "           Linear-12                  [-1, 160]         409,760\n",
      "             ReLU-13                  [-1, 160]               0\n",
      "           Linear-14                 [-1, 2560]         412,160\n",
      "           Conv2d-15       [-1, 1280, 128, 128]       3,278,080\n",
      "      ChannelGate-16       [-1, 1280, 128, 128]               0\n",
      "           Conv2d-17       [-1, 1280, 128, 128]       1,639,680\n",
      "================================================================\n",
      "Total params: 6,767,760\n",
      "Trainable params: 6,767,760\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 80.00\n",
      "Forward/backward pass size (MB): 640.11\n",
      "Params size (MB): 25.82\n",
      "Estimated Total Size (MB): 745.93\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(net, (256*5, 128, 128), device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.0\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
